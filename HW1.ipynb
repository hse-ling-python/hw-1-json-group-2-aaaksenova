{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –î–æ–º–∞—à–Ω—è—è —Ä–∞–±–æ—Ç–∞ 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ê–∫—Å–µ–Ω–æ–≤–∞ –ê–Ω–Ω–∞ –ë–ö–õ182"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∏ –º–æ–¥—É–ª–∏, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–Ω–∞–¥–æ–±—è—Ç—Å—è –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import collections\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°—á–∏—Ç—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç –∏ –∫–ª–∞–¥–µ–º –µ–≥–æ –∫–∞–∫ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = ([json.loads(line) for line in \n",
    "           open('hw_3_twitter.json', 'r', encoding='utf-8')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ó–∞–¥–∞–Ω–∏–µ 1**\n",
    "\n",
    "–ö–∞–∂–¥—ã–π —Ç–≤–∏—Ç - –æ—Ç–¥–µ–ª—å–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å, –∑–Ω–∞—á–∏—Ç, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–≤–∏—Ç–æ–≤ - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤–∞—Ä–µ–π –≤ —Å–ø–∏—Å–∫–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–≤–∏—Ç–æ–≤: 2556\n"
     ]
    }
   ],
   "source": [
    "print('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–≤–∏—Ç–æ–≤: ', end='')\n",
    "print(len(tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ó–∞–¥–∞–Ω–∏–µ 2**\n",
    "\n",
    "–í —É–¥–∞–ª–µ–Ω–Ω—ã—Ö —Ç–≤–∏—Ç–∞—Ö –µ—Å—Ç—å –∫–ª—é—á *'delete'*. –ü–æ—Å—á–∏—Ç–∞–µ–º —Ç–∞–∫–∏–µ —Ç–≤–∏—Ç—ã –∏ —Ä–∞–∑–¥–µ–ª–∏–º –∏—Ö –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—Å–µ—Ö —Ç–≤–∏—Ç–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ü—Ä–æ—Ü–µ–Ω—Ç —É–¥–∞–ª–µ–Ω–Ω—ã—Ö —Ç–≤–∏—Ç–æ–≤: 14.162754303599373%\n"
     ]
    }
   ],
   "source": [
    "deleted = 0  # –°—á–µ—Ç—á–∏–∫\n",
    "for i in range(len(tweets)):  # –ü—Ä–æ—Ö–æ–¥–∏–º—Å—è –ø–æ –≤—Å–µ–º —Ç–≤–∏—Ç–∞–º —á–µ—Ä–µ–∑ –∏–Ω–¥–µ–∫—Å, —Ç–∫ tweets - —Å–ø–∏—Å–æ–∫\n",
    "    if 'delete' in tweets[i].keys():\n",
    "        deleted += 1\n",
    "print('–ü—Ä–æ—Ü–µ–Ω—Ç —É–¥–∞–ª–µ–Ω–Ω—ã—Ö —Ç–≤–∏—Ç–æ–≤: ', end='')\n",
    "print(str(deleted / len(tweets) * 100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ó–∞–¥–∞–Ω–∏–µ 3**\n",
    "\n",
    "–ó–∞ —è–∑—ã–∫ —Ç–≤–∏—Ç–∞ –æ—Ç–≤–µ—á–∞–µ—Ç –∫–ª—é—á *'lang'*, —Å–æ–±–µ—Ä–µ–º –∫—É—á—É —è–∑—ã–∫–æ–≤, –∞ –ø–æ—Ç–æ–º —Å –ø–æ–º–æ—â—å—é *Counter* –ø–æ—Å—á–∏—Ç–∞–µ–º —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –≤—Å—Ç—Ä–µ—á–∞–ª—Å—è –∫–∞–∂–¥—ã–π —è–∑—ã–∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–Ø–∑—ã–∫\t\t–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–≤–∏—Ç–æ–≤\n",
      "en\t\t719\n",
      "ja\t\t438\n",
      "es\t\t173\n",
      "ko\t\t149\n",
      "th\t\t123\n",
      "ar\t\t119\n",
      "und\t\t117\n",
      "in\t\t71\n",
      "pt\t\t69\n",
      "fr\t\t35\n"
     ]
    }
   ],
   "source": [
    "languages = []  # –°—é–¥–∞ –º—ã –±—É–¥–µ–º —Å–∫–ª–∞–¥—ã–≤–∞—Ç—å —è–∑—ã–∫–∏ –∫–∞–∂–¥–æ–≥–æ —Ç–≤–∏—Ç–∞\n",
    "for i in range(len(tweets)):\n",
    "    for key, value in tweets[i].items():\n",
    "        if key == 'lang':\n",
    "            languages.append(value)\n",
    "lang_rates = collections.Counter(languages).most_common()  # –°—á–∏—Ç–∞–µ–º —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –∫–∞–∂–¥—ã–π —è–∑—ã–∫ \n",
    "# –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º –≤ –ø–æ—Ä—è–¥–∫–µ —É–±—ã–≤–∞–Ω–∏—è —á–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç–∏\n",
    "print('–Ø–∑—ã–∫'+'\\t\\t'+'–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–≤–∏—Ç–æ–≤')\n",
    "for i in range(10):\n",
    "    print(str(lang_rates[i][0]) + '\\t\\t' + str(lang_rates[i][1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ó–∞–¥–∞–Ω–∏–µ 4**\n",
    "\n",
    "–£ –∫–∞–∂–¥–æ–≥–æ —Ç–≤–∏—Ç–∞ –µ—Å—Ç—å id –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –µ–≥–æ —Å–æ–∑–¥–∞–≤—à–µ–≥–æ. –ê–ª–≥–æ—Ä–∏—Ç–º —Ä–µ—à–µ–Ω–∏—è —Ç–∞–∫–æ–π –∂–µ, –∫–∞–∫ –≤ –∑–∞–¥–∞–Ω–∏–∏ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –∏–º–µ—é—â–∏—Ö –±–æ–ª–µ–µ –æ–¥–Ω–æ–≥–æ —Ç–≤–∏—Ç–∞: 25\n"
     ]
    }
   ],
   "source": [
    "users = []  # –°–∫–ª–∞–¥—ã–≤–∞–µ–º —Å—é–¥–∞ id –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
    "for i in range(len(tweets)):\n",
    "    if 'delete' not in tweets[i].keys():\n",
    "        users.append(tweets[i][\"user\"][\"id\"])\n",
    "users = collections.Counter(users)\n",
    "active_users = 0  # –°—á–µ—Ç—á–∏–∫\n",
    "for key, value in users.items():\n",
    "    if value > 1: \n",
    "        active_users += 1\n",
    "print('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –∏–º–µ—é—â–∏—Ö –±–æ–ª–µ–µ –æ–¥–Ω–æ–≥–æ —Ç–≤–∏—Ç–∞:',\n",
    "      active_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ó–∞–¥–∞–Ω–∏–µ 5**\n",
    "\n",
    "–•—ç—à—Ç—ç–≥–∏ –ª–µ–∂–∞—Ç –≤ *'entities'* –≤ –∑–Ω–∞—á–µ–Ω–∏—è—Ö –∫–ª—é—á–∞ *'hashtags'*. –ü—Ä–∏ —ç—Ç–æ–º —Ö—ç—à—Ç—ç–≥–∏ - —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π, –∫–æ—Ç–æ—Ä—ã–π —Ç–æ–∂–µ –Ω—É–∂–Ω–æ —Ä–∞—Å–ø–∞–∫–æ–≤–∞—Ç—å. –î–ª—è –ø–æ–¥—Å—á–µ—Ç–æ–≤ —Å–∞–º—ã—Ö –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Ö—ç—à—Ç–µ–≥–æ–≤ –ø–æ–ª—å–∑—É–µ–º—Å—è –≤—Å–µ —Ç–µ–º –∂–µ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–¢–æ–ø —Å–∞–º—ã—Ö –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Ö—ç—à—Ç–µ–≥–æ–≤\n",
      "1. BTS\n",
      "2. Î∞©ÌÉÑÏÜåÎÖÑÎã®\n",
      "3. AMAs\n",
      "4. ‰∫∫Ê∞óÊäïÁ•®„Ç¨„ÉÅ„É£\n",
      "5. ÌÉúÌòï\n",
      "6. Î∑î\n",
      "7. BTSinChicago\n",
      "8. BTSLoveYourselfTour\n",
      "9. Ïò§ÎäòÏùòÎ∞©ÌÉÑ\n",
      "10. PledgeForSwachhBharat\n",
      "11. MPN\n",
      "12. PCAs\n",
      "13. V\n",
      "14. ÏãúÏπ¥Í≥†1ÌöåÏ∞®Í≥µÏó∞\n",
      "15. ‡πÄ‡∏õ‡πä‡∏Å‡∏ú‡∏•‡∏¥‡∏ï‡πÇ‡∏ä‡∏Ñ\n",
      "16. JIMIN\n",
      "17. running\n",
      "18. NCT\n",
      "19. ÏßÄÎØº\n",
      "20. WajahmuPlastik\n"
     ]
    }
   ],
   "source": [
    "hashtags = []  # –°–∫–ª–∞–¥—ã–≤–∞–µ–º —Å—é–¥–∞ –≤—Å–µ —Ö—ç—à—Ç–µ–≥–∏\n",
    "for i in range(len(tweets)):\n",
    "    if 'delete' not in tweets[i].keys():\n",
    "        hash_list = tweets[i][\"entities\"][\"hashtags\"]\n",
    "        hashtags.extend([hash_list[i][\"text\"] for i in range(len(hash_list))])\n",
    "hashtags = collections.Counter(hashtags).most_common()\n",
    "print('–¢–æ–ø —Å–∞–º—ã—Ö –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Ö—ç—à—Ç–µ–≥–æ–≤')\n",
    "for i in range(20):\n",
    "    print(str(i + 1) + '. ' + str(hashtags[i][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ó–∞–¥–∞–Ω–∏–µ 6** \n",
    "\n",
    "*(–ø—Ä–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–µ –ö–∞—Ç–∏ –¢–∞–∫—Ç–∞—à–µ–≤–æ–π)*\n",
    "\n",
    "–ù–∞–π–¥–µ–º —Å–∞–º—ã–µ —á–∞—Å—Ç–æ—Ç–Ω—ã–µ —Å–ª–æ–≤–∞. –¢–µ–∫—Å—Ç —Ç–≤–∏—Ç–∞ –ª–µ–∂–∏—Ç –≤ –∑–Ω–∞—á–µ–Ω–∏–∏ –∫–ª—é—á–∞ *'text'*, –µ–≥–æ –Ω—É–∂–Ω–æ –æ—á–∏—Å—Ç–∏—Ç—å –æ—Ç –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏, —Å—Å—ã–ª–æ–∫, —Ö—ç—à—Ç–µ–≥–æ–≤ –∏ —Ö—ç–Ω–¥–ª–æ–≤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–Ω–∞–¥–æ–±—è—Ç—Å—è –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞:\n",
    "punctuation = (list(\"\"\".,‚Ä¶;:!‚Äù?$%^&*‚Ññ()_‚Äî=+|[]{}\\/\"<>`~¬±¬ß¬´¬ª¬∞1234567890\"\"\") \n",
    "               + ['- ', ' -', ' - ', \" '\", \"' \"]) # –Ω–µ —É–¥–∞–ª—è–µ–º \"-\", –ø–æ—Ç–æ–º—É —á—Ç–æ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –≤ –∫–æ–º–ø–æ–∑–∏—Ç–∞—Ö\n",
    "links = r'http.+?($|\\s)'  # —Ä–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Å—Å—ã–ª–æ–∫\n",
    "handles = r'@.*?($|\\s)'  # —Ä–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Ö—ç–Ω–¥–ª–æ–≤\n",
    "hashs = r'#.*?($|\\s)'  # —Ä–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Ö—ç—à—Ç–µ–≥–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–†–µ–π—Ç–∏–Ω–≥ —á–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç–∏ —Å–ª–æ–≤ —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –≤—Ö–æ–∂–¥–µ–Ω–∏–π\n",
      "1. the\t\t107\n",
      "2. to\t\t79\n",
      "3. a\t\t68\n",
      "4. i\t\t61\n",
      "5. and\t\t57\n",
      "6. you\t\t45\n",
      "7. is\t\t41\n",
      "8. of\t\t41\n",
      "9. for\t\t40\n",
      "10. it\t\t38\n"
     ]
    }
   ],
   "source": [
    "parced = []  # —Å—é–¥–∞ –º—ã —Å–∫–ª–∞–¥—ã–≤–∞–µ–º —Å–ª–æ–≤–∞\n",
    "for i in range(len(tweets)):\n",
    "    if ((\"retweeted_status\" not in tweets[i].keys()) and (\"quoted_status\" not in tweets[i].keys())\n",
    "        and ('delete' not in tweets[i].keys()) and (tweets[i]['lang'] == 'en')):\n",
    "        text = tweets[i][\"text\"]\n",
    "        for char in punctuation:\n",
    "            text = text.strip().replace(char, '')\n",
    "        text = re.sub(links, r'', text)  # —É–±–∏—Ä–∞–µ–º —Å—Å—ã–ª–∫–∏\n",
    "        text = re.sub(handles, r'', text)  # —É–±–∏—Ä–∞–µ–º —Ö—ç–Ω–¥–ª—ã\n",
    "        text = re.sub(hashs, r'', text)  # —É–±–∏—Ä–∞–µ–º —Ö—ç—à—Ç–µ–≥–∏\n",
    "        text = re.sub(r'[^a-zA-Z\\'\\s-]', r'', text) # —É–±–∏—Ä–∞–µ–º —Å–º–∞–π–ª–∏–∫–∏ –∏ —Ç.–ø.\n",
    "        text = text.lower()\n",
    "        list_of_words = text.split()\n",
    "        parced.extend(list_of_words)\n",
    "common_words = collections.Counter(parced).most_common()\n",
    "print('–†–µ–π—Ç–∏–Ω–≥ —á–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç–∏ —Å–ª–æ–≤ —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –≤—Ö–æ–∂–¥–µ–Ω–∏–π')\n",
    "for i in range(10):\n",
    "    print((str(i + 1) + '. ' + str(common_words[i][0]) \n",
    "           + '\\t\\t' + str(common_words[i][1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ó–∞–¥–∞–Ω–∏–µ 7**\n",
    "\n",
    "–ù–∞–π–¥–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ–ª–ª–æ–≤–µ—Ä–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (*'user'*). –î–ª—è —ç—Ç–æ–≥–æ —Å–æ–∑–¥–∞–¥–∏–º —Å–ª–æ–≤–∞—Ä—å —Å –∫–ª—é—á–∞–º–∏ - –∏–º–µ–Ω–∞–º–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π (*'name'*) –∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Ñ–æ–ª–ª–æ–≤–µ—Ä–æ–≤ (*'follower_count'*). –ó–∞—Ç–µ–º –æ—Ç—Å–æ—Ä—Ç–∏—Ä—É–µ–º —Å–ª–æ–≤–∞—Ä—å –ø–æ –∑–Ω–∞—á–µ–Ω–∏—è–º."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ò–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è \t –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ–ª–ª–æ–≤–µ—Ä–æ–≤\n",
      "Filosof√≠a‚ôï \t\t 2521403\n",
      "FITNESS Magazine \t\t 1491309\n",
      "malaysiakini.com \t\t 1206759\n",
      "NYT Science \t\t 1137374\n",
      "Gram√°tica \t\t 625463\n",
      "TGRT Haber \t\t 392472\n",
      "The Sun Football ‚öΩ \t\t 383698\n",
      "Melbourne, Australia \t\t 374222\n",
      "Roznama Express \t\t 318189\n",
      "üíû ·É™≈≥‡Ωû…†…õ‡Ωû·É™∆°∆°…†ƒ±…õ üíû \t\t 311319\n"
     ]
    }
   ],
   "source": [
    "popular_users = {}  # C–ª–æ–≤–∞—Ä—å –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
    "for i in range(len(tweets)):\n",
    "    if 'delete' not in tweets[i].keys():\n",
    "        popular_users[tweets[i]['user']['name']] = tweets[i]['user']['followers_count']\n",
    "count = 0  # –°—á–µ—Ç—á–∏–∫ –¥–ª—è –ø–µ—á–∞—Ç–∏\n",
    "print('–ò–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è', '\\t', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ–ª–ª–æ–≤–µ—Ä–æ–≤')\n",
    "for user in sorted(popular_users, key=popular_users.get, reverse=True):\n",
    "    print(user, '\\t\\t', popular_users[user])\n",
    "    count += 1\n",
    "    if count == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ó–∞–¥–∞–Ω–∏–µ 8**\n",
    "\n",
    "–ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –ª–µ–∂–∞—Ç –≤ –∑–Ω–∞—á–µ–Ω–∏—è—Ö –∫–ª—é—á–∞ *'source'*. –ü—Ä–∏ —ç—Ç–æ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π –∏–º–µ—é—Ç –≤–∏–¥ *>**Application**</a*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–¢–æ–ø —Å–∞–º—ã—Ö –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π –¥–ª—è —Ç–≤–∏—Ç–æ–≤\n",
      "1. Twitter for iPhone\n",
      "2. Twitter for Android\n",
      "3. Twitter Web Client\n",
      "4. twittbot.net\n",
      "5. Twitter Lite\n",
      "6. Twitter for iPad\n",
      "7. TweetDeck\n",
      "8. Facebook\n",
      "9. IFTTT\n",
      "10. ÿ™ÿ∑ÿ®ŸäŸÇ ŸÇÿ±ÿ¢ŸÜŸä\n"
     ]
    }
   ],
   "source": [
    "apps = [] # –°—é–¥–∞ —Å–∫–ª–∞–¥—ã–≤–∞–µ–º –≤—Å–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –¥–ª—è —Ç–≤–∏—Ç–æ–≤\n",
    "for i in range(len(tweets)):\n",
    "    if 'delete' not in tweets[i].keys():\n",
    "        source = tweets[i]['source']\n",
    "        source = re.search(r'>(.+?)</a>', source)\n",
    "        apps.append(source.group(1))\n",
    "apps = collections.Counter(apps).most_common()\n",
    "print('–¢–æ–ø —Å–∞–º—ã—Ö –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π –¥–ª—è —Ç–≤–∏—Ç–æ–≤')\n",
    "for i in range(10):\n",
    "    print(str(i + 1) + '. ' + apps[i][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
